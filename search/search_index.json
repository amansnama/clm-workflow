{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the clm-workflow documentation clm-workflow automates the steps to run Community Land Model version 5 (CLM5) hosted at CTSM .It also automates CLM output analysis, if you want it to. :) NOTE : The first part of the workflow is complete and works. The second part (CLM analysis) is under preparation. Documentation structure Workflow Tutorial Workflow User's Guide Workflow Reference Workflow Components The workflow contains two main components: CLM simulation automation Analysis automation NOTE : This workflow is still in development. The scripts for analysis are available in the repo, but they have not been implemented in Snakemake. The documentation is also in development. Getting help Please contact me at shrest66@msu.edu with any issues regarding clm-workflow .","title":"Home"},{"location":"#welcome-to-the-clm-workflow-documentation","text":"clm-workflow automates the steps to run Community Land Model version 5 (CLM5) hosted at CTSM .It also automates CLM output analysis, if you want it to. :) NOTE : The first part of the workflow is complete and works. The second part (CLM analysis) is under preparation.","title":"Welcome to the clm-workflow documentation"},{"location":"#documentation-structure","text":"Workflow Tutorial Workflow User's Guide Workflow Reference","title":"Documentation structure"},{"location":"#workflow-components","text":"The workflow contains two main components: CLM simulation automation Analysis automation NOTE : This workflow is still in development. The scripts for analysis are available in the repo, but they have not been implemented in Snakemake. The documentation is also in development.","title":"Workflow Components"},{"location":"#getting-help","text":"Please contact me at shrest66@msu.edu with any issues regarding clm-workflow .","title":"Getting help"},{"location":"reference/","text":"Workflow References Workflow Design Workflow Dataflow diagram (DFD)","title":"Overview"},{"location":"reference/#workflow-references","text":"Workflow Design Workflow Dataflow diagram (DFD)","title":"Workflow References"},{"location":"reference/design/","text":"clm-workflow Design Introduction The goal of this workflow is to automate the bazillion steps of running CLM simulations in a highly reproducible manner. In addition, the secondary goal is to analyze the outputs of CLM simulations if CLM runs successfully. Finally, the workflow needs to provide a simulation report for successful and failed workflow runs. Design Considerations CLM5 is developed, tested, and supported in NCAR machines. It is difficult but possible to run CLM5 in non-NCAR machines. A check for NCAR or non-NCAR machine will need to be included in the CLM simulation part of the workflow. The analysis workflow consists of number of Python scripts and Jupyter notebooks. These depend on a set of libraries. So, a Python environment with a specific Python version and dependent libraries need to be installed. Users should be provided the choice to run only CLM simulation, only output analysis, or both parts of the workflow. Constraints The snakemake workflow philosophy needs a 'master' job to be running in a batch job style system. For NCAR's derecho machine specifically, any job has a maximum allowable run time of 12 hours. So, even if a ./case.submit job of 12 hours starts instantly with the master job, there will not be adequate time to run the analysis part of the workflow. A solution might be to split the master job into two master jobs: first for CLM simulation, and second for output analysis. Algorithm or pseudocode of the main workflow components # Created on 2024/09/10 by Aman Shrestha # Pseudocode #--------------------------------------------------------------------- module CLM_job: # Module for CLM part of workflow function setup_CLM(forcing, surface, src_files, build_settings): build CLM if build fails: exit else: print Build successful return CLM_executable function prepare_config_files(par1, par2, par3,...): set configurations for each parameter return config function run_CLM(CLM executable, config): submit job to batch system if run fails: print Run fail exit else: print Run successful with config store outputs return path_to_output module Analyze_Plot(): # Module for analysis and visualization function streamflow(model, obs): calculate metrics using python packages plot model vs obs streamflow hydrographs plot metrics spatial distribution map plot box and whisker plot of metric # need to add more functions for other variables. # They look similar to the streamflow function above. #--------------------------------------------------------------------- # Workflow start log in to machine define xml_parameters define run_config CLM_executable = CLM_job.setup_CLM(forcing, surface) for sim_time=[5days, 1year, nyear]: if sim_time==5days: job_wallclock_time=30min else if sim_time==1year: job_wallclock_time=6hr else: job_wallclock_time=12hr config = CLM_job.prepare_config_files(sim_time, job_wallclock_time, xml_parameters) output_path = CLM_job.run_CLM(CLM_executable, run_config) # Download data from machine1 to machine2 # This should be only done once. # rsync -r machine1:output_path machine2:archive # Pick what output variables to analyze define vars # Analyze and plot # needs a mapping table which points var to corresponding analyze function for vars in vars_to_analyze: Analyze_Plot.streamflow(archive, observation_dataset) # Analyze_Plot.function2 and so on... notify user when it finishes # Workflow end","title":"Workflow Design"},{"location":"reference/design/#clm-workflow-design","text":"","title":"clm-workflow Design"},{"location":"reference/design/#introduction","text":"The goal of this workflow is to automate the bazillion steps of running CLM simulations in a highly reproducible manner. In addition, the secondary goal is to analyze the outputs of CLM simulations if CLM runs successfully. Finally, the workflow needs to provide a simulation report for successful and failed workflow runs.","title":"Introduction"},{"location":"reference/design/#design-considerations","text":"CLM5 is developed, tested, and supported in NCAR machines. It is difficult but possible to run CLM5 in non-NCAR machines. A check for NCAR or non-NCAR machine will need to be included in the CLM simulation part of the workflow. The analysis workflow consists of number of Python scripts and Jupyter notebooks. These depend on a set of libraries. So, a Python environment with a specific Python version and dependent libraries need to be installed. Users should be provided the choice to run only CLM simulation, only output analysis, or both parts of the workflow.","title":"Design Considerations"},{"location":"reference/design/#constraints","text":"The snakemake workflow philosophy needs a 'master' job to be running in a batch job style system. For NCAR's derecho machine specifically, any job has a maximum allowable run time of 12 hours. So, even if a ./case.submit job of 12 hours starts instantly with the master job, there will not be adequate time to run the analysis part of the workflow. A solution might be to split the master job into two master jobs: first for CLM simulation, and second for output analysis.","title":"Constraints"},{"location":"reference/design/#algorithm-or-pseudocode-of-the-main-workflow-components","text":"# Created on 2024/09/10 by Aman Shrestha # Pseudocode #--------------------------------------------------------------------- module CLM_job: # Module for CLM part of workflow function setup_CLM(forcing, surface, src_files, build_settings): build CLM if build fails: exit else: print Build successful return CLM_executable function prepare_config_files(par1, par2, par3,...): set configurations for each parameter return config function run_CLM(CLM executable, config): submit job to batch system if run fails: print Run fail exit else: print Run successful with config store outputs return path_to_output module Analyze_Plot(): # Module for analysis and visualization function streamflow(model, obs): calculate metrics using python packages plot model vs obs streamflow hydrographs plot metrics spatial distribution map plot box and whisker plot of metric # need to add more functions for other variables. # They look similar to the streamflow function above. #--------------------------------------------------------------------- # Workflow start log in to machine define xml_parameters define run_config CLM_executable = CLM_job.setup_CLM(forcing, surface) for sim_time=[5days, 1year, nyear]: if sim_time==5days: job_wallclock_time=30min else if sim_time==1year: job_wallclock_time=6hr else: job_wallclock_time=12hr config = CLM_job.prepare_config_files(sim_time, job_wallclock_time, xml_parameters) output_path = CLM_job.run_CLM(CLM_executable, run_config) # Download data from machine1 to machine2 # This should be only done once. # rsync -r machine1:output_path machine2:archive # Pick what output variables to analyze define vars # Analyze and plot # needs a mapping table which points var to corresponding analyze function for vars in vars_to_analyze: Analyze_Plot.streamflow(archive, observation_dataset) # Analyze_Plot.function2 and so on... notify user when it finishes # Workflow end","title":"Algorithm or pseudocode of the main workflow components"},{"location":"reference/dfd/","text":"clm-workflow DFD","title":"Workflow DFD"},{"location":"reference/dfd/#clm-workflow-dfd","text":"","title":"clm-workflow DFD"},{"location":"tutorial/","text":"Overview The tutorial is seperated into three options based on which part(s) of the workflow the user will be running. The tutorial assumes the user will be running the workflow in a NCAR machine, specifically derecho . The advantages of running in a NCAR machine in comparison to a local machine are: CLM simulations are computationally intensive and perform poorly in local machines or servers. NCAR hosts advanced supercomputing systems where they develop and test CLM. Inputs required to run CLM simulations occupy huge space. A 40 year simulation could require ~500GB of atmospheric forcing data. The memory requirements also increase exponentially with finer resolution. It is possible to run CLM in a non-NCAR machine; however, it requires major effort. Tutorial Prerequisite Installing CTSM Installing CTSM (CTSM hosts CLM) is straightforward. Clone CTSM from their github repo . $ git clone https://github.com/ESCOMP/CTSM By default, the clone command clones the latest commit from the master branch. The CTSM developers provide tags for incremental developments. To get a specific tag, say tag ctsm5.2.001, run: $ git checkout ctsm5.2.001 clm-workflow needs to be informed where CTSM is installed. The path to CTSM is provided to the variable CTSMDIR in caseconfig.cfg . Throughout these tutorials, CTSMDIR should be the path where you installed CTSM. CTSM is not fully installed yet. CTSM depends upon various dependencies which are linked to CTSM as git submodules. These can be installed by running # For ctsm<5.2 $ cd CTSMDIR $ ./manage_externals/checkout_externals # For ctsm>5.2 $ cd CTSMDIR $ ./bin/git-fleximod update Please go through NCAR's CTSM tutorial for more information on runnning CTSM. Installing snakemake Follow the steps to install snakemake here $ conda create -c conda-forge -c bioconda -n snakemake snakemake clm-workflow Installation Clone the clm-workflow repo https://github.com/amansnama/clm-workflow to your machine. $ git clone https://github.com/amansnama/clm-workflow Workflow Tutorials CLM simulation workflow tutorial Analysis workflow tutorial Combined CLM-analysis workflow tutorial","title":"Tutorial"},{"location":"tutorial/#overview","text":"The tutorial is seperated into three options based on which part(s) of the workflow the user will be running. The tutorial assumes the user will be running the workflow in a NCAR machine, specifically derecho . The advantages of running in a NCAR machine in comparison to a local machine are: CLM simulations are computationally intensive and perform poorly in local machines or servers. NCAR hosts advanced supercomputing systems where they develop and test CLM. Inputs required to run CLM simulations occupy huge space. A 40 year simulation could require ~500GB of atmospheric forcing data. The memory requirements also increase exponentially with finer resolution. It is possible to run CLM in a non-NCAR machine; however, it requires major effort.","title":"Overview"},{"location":"tutorial/#tutorial-prerequisite","text":"","title":"Tutorial Prerequisite"},{"location":"tutorial/#installing-ctsm","text":"Installing CTSM (CTSM hosts CLM) is straightforward. Clone CTSM from their github repo . $ git clone https://github.com/ESCOMP/CTSM By default, the clone command clones the latest commit from the master branch. The CTSM developers provide tags for incremental developments. To get a specific tag, say tag ctsm5.2.001, run: $ git checkout ctsm5.2.001 clm-workflow needs to be informed where CTSM is installed. The path to CTSM is provided to the variable CTSMDIR in caseconfig.cfg . Throughout these tutorials, CTSMDIR should be the path where you installed CTSM. CTSM is not fully installed yet. CTSM depends upon various dependencies which are linked to CTSM as git submodules. These can be installed by running # For ctsm<5.2 $ cd CTSMDIR $ ./manage_externals/checkout_externals # For ctsm>5.2 $ cd CTSMDIR $ ./bin/git-fleximod update Please go through NCAR's CTSM tutorial for more information on runnning CTSM.","title":"Installing CTSM"},{"location":"tutorial/#installing-snakemake","text":"Follow the steps to install snakemake here $ conda create -c conda-forge -c bioconda -n snakemake snakemake","title":"Installing snakemake"},{"location":"tutorial/#clm-workflow-installation","text":"Clone the clm-workflow repo https://github.com/amansnama/clm-workflow to your machine. $ git clone https://github.com/amansnama/clm-workflow","title":"clm-workflow Installation"},{"location":"tutorial/#workflow-tutorials","text":"","title":"Workflow Tutorials"},{"location":"tutorial/#clm-simulation-workflow-tutorial","text":"","title":"CLM simulation workflow tutorial"},{"location":"tutorial/#analysis-workflow-tutorial","text":"","title":"Analysis workflow tutorial"},{"location":"tutorial/#combined-clm-analysis-workflow-tutorial","text":"","title":"Combined CLM-analysis workflow tutorial"},{"location":"tutorial/clm-analysis/","text":"Analysis workflow tutorial This tutorial shows the workflow to automate the analysis of CLM outputs. This workflow is the second part of clm-workflow ; it analyzes the outputs after successful completion of the CLM simulation workflow. However, this workflow is intended to be able to run seperately from the first part. If you have outputs from a previous CLM run, you should be able to use this workflow to analyze it. NOTE : The documentation is in development.","title":"Analysis workflow tutorial"},{"location":"tutorial/clm-analysis/#analysis-workflow-tutorial","text":"This tutorial shows the workflow to automate the analysis of CLM outputs. This workflow is the second part of clm-workflow ; it analyzes the outputs after successful completion of the CLM simulation workflow. However, this workflow is intended to be able to run seperately from the first part. If you have outputs from a previous CLM run, you should be able to use this workflow to analyze it. NOTE : The documentation is in development.","title":"Analysis workflow tutorial"},{"location":"tutorial/clm-sim-tutorial/","text":"CLM simulation workflow tutorial This tutorial walks through the workflow to automate CLM simulations. Please ensure that CTSM is installed. The path where we installed CTSM is called CTSMDIR , throughout the tutorial and by clm-workflow . CLM simulations are called cases. The manual way to create and run a CLM case would be to: Create new case. Run case setup. Configure the settings that the CLM case will run on. Build the case. Submit the case run to a batch job queue. clm-workflow automates all of the above steps. We instruct the workflow how we want the CLM case to be created, configured, and ran. These settings are specified in two files: caseconfig.cfg and xmlconfig.cfg inside the directory clm_scripts. First, we will look inside caseconfig.cfg . It contains the variables CASENAME, CTSMDIR, CASEDIR, RES, COMPSET, XMLCONFIG, and ARCHIVE . CASENAME : Name to identify the case. Can be anything. CTSMDIR : Location of CTSM installation. CASEDIR : Location to save new cases. RES : CLM simulation spatial resolution. Valid RES values can be queried by running CTSMDIR/cime/scripts/query_config --res . COMPSET : CLM component sets. Valid COMPSET can be queried by running CTSMDIR/cime/scripts/query_config --compsets clm . XMLCONFIG : Location of xmlconfig.cfg file. The xmlconfig.cfg contains CLM xml build and run configurations. ARCHIVE : Location to save CLM simulation outputs. The outputs may require a large storage space. CASENAME=\"name_to_identify_case\", CTSMDIR=\"path_to_ctsm\", CASEDIR=\"path_to_store_CASENAME\", RES=\"CLM_grid_resolution\", COMPSET=\"CLM_compset\", XMLCONFIG=\"path_to_xmlconfig.cfg\", ARCHIVE=\"path_to_CTSM_archive\" Derecho requires a mandatory project account to bill compute hour uses. Other machines might also require a project account. So, create an environment variable PRJ and store your project account in it. We will create PRJ in a .profile file in your home directory. $ cd ~ $ echo 'PRJ=YOUR_PROJECT_ACCOUNT;export PRJ'>>.profile This will add PRJ to an environment variable after a new login. To make it available in the current login, run: $ source ~/.profile xmlconfig.cfg contains xml configurations which define a CLM run. All possible xmls can be viewed by running ./xmlquery --listall . It is best to always have xmlconfigs for RUN_STARTDATE, STOP_N, and STOP_OPTION . For this tutorial, we will run CLM for 5 days starting 2000-01-01 and let the maximume job wallclock of 30 minutes. RUN_STARTDATE=2000-01-01 STOP_N=5 STOP_OPTION=ndays JOB_WALLCLOCK_TIME=00:30:00 Activate our snakemake environment. First, we will load conda module. Then activate our snakemake environment snakemake_env . $ ml conda $ conda activate snakemake_env We are all set up to run the workflow! Just type snakemake to run the workflow. $ snakemake","title":"CLM simulation workflow tutorial"},{"location":"tutorial/clm-sim-tutorial/#clm-simulation-workflow-tutorial","text":"This tutorial walks through the workflow to automate CLM simulations. Please ensure that CTSM is installed. The path where we installed CTSM is called CTSMDIR , throughout the tutorial and by clm-workflow . CLM simulations are called cases. The manual way to create and run a CLM case would be to: Create new case. Run case setup. Configure the settings that the CLM case will run on. Build the case. Submit the case run to a batch job queue. clm-workflow automates all of the above steps. We instruct the workflow how we want the CLM case to be created, configured, and ran. These settings are specified in two files: caseconfig.cfg and xmlconfig.cfg inside the directory clm_scripts. First, we will look inside caseconfig.cfg . It contains the variables CASENAME, CTSMDIR, CASEDIR, RES, COMPSET, XMLCONFIG, and ARCHIVE . CASENAME : Name to identify the case. Can be anything. CTSMDIR : Location of CTSM installation. CASEDIR : Location to save new cases. RES : CLM simulation spatial resolution. Valid RES values can be queried by running CTSMDIR/cime/scripts/query_config --res . COMPSET : CLM component sets. Valid COMPSET can be queried by running CTSMDIR/cime/scripts/query_config --compsets clm . XMLCONFIG : Location of xmlconfig.cfg file. The xmlconfig.cfg contains CLM xml build and run configurations. ARCHIVE : Location to save CLM simulation outputs. The outputs may require a large storage space. CASENAME=\"name_to_identify_case\", CTSMDIR=\"path_to_ctsm\", CASEDIR=\"path_to_store_CASENAME\", RES=\"CLM_grid_resolution\", COMPSET=\"CLM_compset\", XMLCONFIG=\"path_to_xmlconfig.cfg\", ARCHIVE=\"path_to_CTSM_archive\" Derecho requires a mandatory project account to bill compute hour uses. Other machines might also require a project account. So, create an environment variable PRJ and store your project account in it. We will create PRJ in a .profile file in your home directory. $ cd ~ $ echo 'PRJ=YOUR_PROJECT_ACCOUNT;export PRJ'>>.profile This will add PRJ to an environment variable after a new login. To make it available in the current login, run: $ source ~/.profile xmlconfig.cfg contains xml configurations which define a CLM run. All possible xmls can be viewed by running ./xmlquery --listall . It is best to always have xmlconfigs for RUN_STARTDATE, STOP_N, and STOP_OPTION . For this tutorial, we will run CLM for 5 days starting 2000-01-01 and let the maximume job wallclock of 30 minutes. RUN_STARTDATE=2000-01-01 STOP_N=5 STOP_OPTION=ndays JOB_WALLCLOCK_TIME=00:30:00 Activate our snakemake environment. First, we will load conda module. Then activate our snakemake environment snakemake_env . $ ml conda $ conda activate snakemake_env We are all set up to run the workflow! Just type snakemake to run the workflow. $ snakemake","title":"CLM simulation workflow tutorial"},{"location":"user-guide/","text":"Overview This section is intended for researchers who are primarily interested in automating CLM simulations and/or analysis. NOTE : The user guide is currently under development. The user guide is structured into these sections: How-To Install CTSM Download input data for CTSM simulation Set up CTSM in non-NCAR machine Setup conda environment","title":"User Guide"},{"location":"user-guide/#overview","text":"This section is intended for researchers who are primarily interested in automating CLM simulations and/or analysis. NOTE : The user guide is currently under development. The user guide is structured into these sections: How-To Install CTSM Download input data for CTSM simulation Set up CTSM in non-NCAR machine Setup conda environment","title":"Overview"},{"location":"user-guide/how-to/CTSM-setup-nonNCARmachine/","text":"Configuring CTSM in non-NCAR machine To run CTSM in an unsupported machine, users need to modify three xml files: - config_machines.xml - config_batch.xml - config_compiler.xml MSU HPCC For MSU's HPCC, ICER provides a lab notebook to configure CTSM. A working xml configurations is available for HPCC's dev-amd20 compute system at https://github.com/amansnama/cime_config_HPCC_MSU .","title":"Configuring CTSM in non-NCAR machine"},{"location":"user-guide/how-to/CTSM-setup-nonNCARmachine/#configuring-ctsm-in-non-ncar-machine","text":"To run CTSM in an unsupported machine, users need to modify three xml files: - config_machines.xml - config_batch.xml - config_compiler.xml","title":"Configuring CTSM in non-NCAR machine"},{"location":"user-guide/how-to/CTSM-setup-nonNCARmachine/#msu-hpcc","text":"For MSU's HPCC, ICER provides a lab notebook to configure CTSM. A working xml configurations is available for HPCC's dev-amd20 compute system at https://github.com/amansnama/cime_config_HPCC_MSU .","title":"MSU HPCC"},{"location":"user-guide/how-to/create-conda-env/","text":"Create conda environment to run workflow To create a conda environment to run clm-workflow, run conda env create -f environment.yaml Activate the env by conda clm-workflow-env","title":"Create conda environment to run workflow"},{"location":"user-guide/how-to/create-conda-env/#create-conda-environment-to-run-workflow","text":"To create a conda environment to run clm-workflow, run conda env create -f environment.yaml Activate the env by conda clm-workflow-env","title":"Create conda environment to run workflow"},{"location":"user-guide/how-to/download-input/","text":"Download input data for CLM simulation CLM simulations require atmospheric forcing data, surface data, parameter data, and model domain meshes. These are available in NCAR's storage system 'GLADE'. CLM simulations in NCAR machine such as derecho or cheyenne are connected to the GLADE file system and therefore do not require users to download the input data. Non-NCAR machine For users running CLM in a non-NCAR machine, input data are automatically downloaded before a CLM job can be submitted. To explicitly check for input data, run from your case directory. $ ./check_input_data To download missing input data, $ ./check_input_data --download","title":"Download input data for CLM simulation"},{"location":"user-guide/how-to/download-input/#download-input-data-for-clm-simulation","text":"CLM simulations require atmospheric forcing data, surface data, parameter data, and model domain meshes. These are available in NCAR's storage system 'GLADE'. CLM simulations in NCAR machine such as derecho or cheyenne are connected to the GLADE file system and therefore do not require users to download the input data.","title":"Download input data for CLM simulation"},{"location":"user-guide/how-to/download-input/#non-ncar-machine","text":"For users running CLM in a non-NCAR machine, input data are automatically downloaded before a CLM job can be submitted. To explicitly check for input data, run from your case directory. $ ./check_input_data To download missing input data, $ ./check_input_data --download","title":"Non-NCAR machine"},{"location":"user-guide/how-to/install-ctsm/","text":"Installing CTSM Clone the CTSM repo to your system. $ git clone https://github.com/ESCOMP/CTSM The git clone command by default clones the most recent commit of the master/main branch. To clone a specific commit, use $ git checkout . Checkout CTSM dependencies. This can be done by running a CTSM command ./manage_externals/checkout_externals/ for ctsm<5.2 or ./bin/git-fleximod update for ctsm>5.2.","title":"Installing CTSM"},{"location":"user-guide/how-to/install-ctsm/#installing-ctsm","text":"Clone the CTSM repo to your system. $ git clone https://github.com/ESCOMP/CTSM The git clone command by default clones the most recent commit of the master/main branch. To clone a specific commit, use $ git checkout . Checkout CTSM dependencies. This can be done by running a CTSM command ./manage_externals/checkout_externals/ for ctsm<5.2 or ./bin/git-fleximod update for ctsm>5.2.","title":"Installing CTSM"}]}